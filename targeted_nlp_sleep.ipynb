{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd8364f6",
   "metadata": {},
   "source": [
    "# NLP Sleep - Targeted Approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a969820",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01c7c73a",
   "metadata": {},
   "source": [
    "### 1. Getting the NLP logic to work\n",
    "The code didn't have all the right formats, but I was just trying to get the program to recognize the string patterns. It was only analyzing a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa7a69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.0, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Sample function to extract AHI and ESS values based on observed patterns\n",
    "def extract_ahi_ess(text):\n",
    "    ahi_value, ess_value = None, None\n",
    "\n",
    "    # Define regex patterns for Total AHI using various formats observed\n",
    "    ahi_patterns = [\n",
    "        r'AHI%:\\s*([\\d\\.]+)',                    # Pattern: AHI%: 11.1\n",
    "        r'AHI:\\s*\\(total\\)::\\s*([\\d\\.]+)',       # Pattern: AHI: (total):: 11.1\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',             # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)\\s*per hour',    # Pattern: Total AHI: 11.1 per hour\n",
    "        r'Total AHI:\\s*([\\d\\.]+)',               # Pattern: Total AHI: 11.1\n",
    "        r'AHI of\\s*([\\d\\.]+)',                   # Pattern: AHI of 1.1\n",
    "        r'pAHI%:\\s*([\\d\\.]+)'                    # Pattern: pAHI%: 11.1\n",
    "    ]\n",
    "\n",
    "    # Define regex patterns for ESS using various formats observed\n",
    "    ess_patterns = [\n",
    "        r'ESS:\\s*([\\d]+)',                        # Pattern: ESS: 11\n",
    "        r'EPWORTH:\\s*([\\d]+)',                    # Pattern: EPWORTH: 1\n",
    "        r'ESS of\\s*([\\d]+)',                      # Pattern: ESS of 11\n",
    "        r'Epworth Sleepiness Scale\\s*:\\s*([\\d]+)', # Pattern: Epworth Sleepiness Scale: 1\n",
    "        r'EPWORTH SLEEPINESS SCALE\\s*:\\s*([\\d]+)' # Pattern: EPWORTH SLEEPINESS SCALE: 1\n",
    "    ]\n",
    "\n",
    "    # Search through AHI patterns to find a match\n",
    "    for pattern in ahi_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ahi_value = float(match.group(1))\n",
    "            break\n",
    "\n",
    "    # Search through ESS patterns to find a match\n",
    "    for pattern in ess_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ess_value = int(match.group(1))\n",
    "            break\n",
    "\n",
    "    return ahi_value, ess_value\n",
    "\n",
    "# Example usage with sample narrative text\n",
    "sample_text = \"AHI of 12, and this is just a bunch of random text to make sure this works Epworth: 6\"\n",
    "total_ahi, ess = extract_ahi_ess(sample_text)\n",
    "extract_ahi_ess\n",
    "# Display the extracted values\n",
    "total_ahi, ess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cee3d899",
   "metadata": {},
   "source": [
    "### 2. Running the NLP Logic on a CSV, not a string\n",
    "This was the first test running the program on a CSV. The program outputted every single column instead of just keeping columns with a value in AHI/ESS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "606d935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to extracted_ahi_ess_values.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract AHI and ESS values based on patterns\n",
    "def extract_ahi_ess(text):\n",
    "    ahi_value, ess_value = None, None\n",
    "\n",
    "    # Define regex patterns for Total AHI based on the given formats\n",
    "    ahi_patterns = [\n",
    "        r'AHI%:\\s*([\\d\\.]+)',                    # Pattern: AHI%: 11.1\n",
    "        r'AHI:\\s*\\(total\\)::\\s*([\\d\\.]+)',       # Pattern: AHI: (total):: 11.1\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',             # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)\\s*per hour',    # Pattern: Total AHI: 11.1 per hour\n",
    "        r'Total AHI:\\s*([\\d\\.]+)',               # Pattern: Total AHI: 11.1\n",
    "        r'AHI of\\s*([\\d\\.]+)',                   # Pattern: AHI of 1.1\n",
    "        r'pAHI%:\\s*([\\d\\.]+)'                    # Pattern: pAHI%: 11.1\n",
    "    ]\n",
    "\n",
    "    # Define regex patterns for ESS based on the given formats\n",
    "    ess_patterns = [\n",
    "        r'ESS:\\s*([\\d]+)',                        # Pattern: ESS: 11\n",
    "        r'EPWORTH:\\s*([\\d]+)',                    # Pattern: EPWORTH: 1\n",
    "        r'ESS of\\s*([\\d]+)',                      # Pattern: ESS of 11\n",
    "        r'Epworth Sleepiness Scale\\s*:\\s*([\\d]+)', # Pattern: Epworth Sleepiness Scale: 1\n",
    "        r'EPWORTH SLEEPINESS SCALE\\s*:\\s*([\\d]+)' # Pattern: EPWORTH SLEEPINESS SCALE: 1\n",
    "    ]\n",
    "\n",
    "    # Search through AHI patterns to find a match\n",
    "    for pattern in ahi_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ahi_value = float(match.group(1))\n",
    "            break\n",
    "\n",
    "    # Search through ESS patterns to find a match\n",
    "    for pattern in ess_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ess_value = int(match.group(1))\n",
    "            break\n",
    "\n",
    "    return ahi_value, ess_value\n",
    "\n",
    "# Function to process a CSV file and extract AHI and ESS values\n",
    "def process_csv(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if 'Narrative' column exists in the file\n",
    "    if 'NARRATIVE' not in data.columns:\n",
    "        print(\"Error: The CSV file must contain a 'Narrative' column with text data.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize lists for extracted data\n",
    "    extracted_data = {\n",
    "        \"NARRATIVE\": [],\n",
    "        \"Total AHI\": [],\n",
    "        \"ESS\": []\n",
    "    }\n",
    "    \n",
    "    # Process each row in the CSV file\n",
    "    for index, row in data.iterrows():\n",
    "        narrative_text = str(row['NARRATIVE'])\n",
    "        ahi_value, ess_value = extract_ahi_ess(narrative_text)\n",
    "        \n",
    "        # Append extracted values\n",
    "        extracted_data[\"NARRATIVE\"].append(narrative_text)\n",
    "        extracted_data[\"Total AHI\"].append(ahi_value)\n",
    "        extracted_data[\"ESS\"].append(ess_value)\n",
    "    \n",
    "    # Create a DataFrame with the extracted results\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "    \n",
    "    # Save the extracted results to a new CSV file\n",
    "    output_path = \"extracted_ahi_ess_values.csv\"\n",
    "    extracted_df.to_csv(output_path, index=False)\n",
    "    print(f\"Extracted data saved to {output_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming the uploaded file is named 'sleep_study_data.csv'\n",
    "file_path = '/Users/dennishwang/Desktop/NLP_sleep/95806A_6k_rows.csv'\n",
    "process_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d7d0045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>Total AHI</th>\n",
       "      <th>ESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaiser Permanente Sleep Laboratory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9985 N. Sierra Avenue, Bldg 7 - Fontana, CA 92335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SLEEP ANALYSIS REPORT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           NARRATIVE  Total AHI  ESS\n",
       "0                 Kaiser Permanente Sleep Laboratory        NaN  NaN\n",
       "1  9985 N. Sierra Avenue, Bldg 7 - Fontana, CA 92335        NaN  NaN\n",
       "2                              SLEEP ANALYSIS REPORT        NaN  NaN\n",
       "3                                                NaN        NaN  NaN\n",
       "4                                                NaN        NaN  NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "458ea4df",
   "metadata": {},
   "source": [
    "### 3. Removing all rows without a value in AHI/ESS columns\n",
    "There was a ton of useless information keeping columns with narrative values like \"Kaiser Permanente Sleep Laboratory\" so I removed them and only kept rows that had a value in the Total AHI or ESS column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41a628e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to extracted_ahi_ess_values.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract AHI and ESS values based on patterns\n",
    "def extract_ahi_ess(text):\n",
    "    ahi_value, ess_value = None, None\n",
    "\n",
    "    # Define regex patterns for Total AHI based on the given formats\n",
    "    ahi_patterns = [\n",
    "        r'AHI%:\\s*([\\d\\.]+)',                    # Pattern: AHI%: 11.1\n",
    "        r'AHI:\\s*\\(total\\)::\\s*([\\d\\.]+)',       # Pattern: AHI: (total):: 11.1\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',             # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)\\s*per hour',    # Pattern: Total AHI: 11.1 per hour\n",
    "        r'Total AHI:\\s*([\\d\\.]+)',               # Pattern: Total AHI: 11.1\n",
    "        r'AHI of\\s*([\\d\\.]+)',                   # Pattern: AHI of 1.1\n",
    "        r'pAHI%:\\s*([\\d\\.]+)'                    # Pattern: pAHI%: 11.1\n",
    "    ]\n",
    "\n",
    "    # Define regex patterns for ESS based on the given formats\n",
    "    ess_patterns = [\n",
    "        r'ESS:\\s*([\\d]+)',                        # Pattern: ESS: 11\n",
    "        r'EPWORTH:\\s*([\\d]+)',                    # Pattern: EPWORTH: 1\n",
    "        r'ESS of\\s*([\\d]+)',                      # Pattern: ESS of 11\n",
    "        r'Epworth Sleepiness Scale\\s*:\\s*([\\d]+)', # Pattern: Epworth Sleepiness Scale: 1\n",
    "        r'EPWORTH SLEEPINESS SCALE\\s*:\\s*([\\d]+)' # Pattern: EPWORTH SLEEPINESS SCALE: 1\n",
    "    ]\n",
    "\n",
    "    # Search through AHI patterns to find a match\n",
    "    for pattern in ahi_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ahi_value = float(match.group(1))\n",
    "            break\n",
    "\n",
    "    # Search through ESS patterns to find a match\n",
    "    for pattern in ess_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ess_value = int(match.group(1))\n",
    "            break\n",
    "\n",
    "    return ahi_value, ess_value\n",
    "\n",
    "# Function to process a CSV file and extract AHI and ESS values\n",
    "def process_csv(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if 'Narrative' column exists in the file\n",
    "    if 'NARRATIVE' not in data.columns:\n",
    "        print(\"Error: The CSV file must contain a 'NARRATIVE' column with text data.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize lists for extracted data\n",
    "    extracted_data = {\n",
    "        \"NARRATIVE\": [],\n",
    "        \"Total AHI\": [],\n",
    "        \"ESS\": []\n",
    "    }\n",
    "    \n",
    "    # Process each row in the CSV file\n",
    "    for index, row in data.iterrows():\n",
    "        narrative_text = str(row['NARRATIVE'])\n",
    "        ahi_value, ess_value = extract_ahi_ess(narrative_text)\n",
    "        \n",
    "        # Append extracted values\n",
    "        extracted_data[\"NARRATIVE\"].append(narrative_text)\n",
    "        extracted_data[\"Total AHI\"].append(ahi_value)\n",
    "        extracted_data[\"ESS\"].append(ess_value)\n",
    "    \n",
    "    # Create a DataFrame with the extracted results\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "    \n",
    "    # Remove rows where both 'Total AHI' and 'ESS' are NaN\n",
    "    extracted_df.dropna(subset=[\"Total AHI\", \"ESS\"], how='all', inplace=True)\n",
    "    \n",
    "    # Save the filtered extracted results to a new CSV file\n",
    "    output_path = \"extracted_ahi_ess_values.csv\"\n",
    "    extracted_df.to_csv(output_path, index=False)\n",
    "    print(f\"Extracted data saved to {output_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming the uploaded file is named 'sleep_study_data.csv'\n",
    "file_path = '/Users/dennishwang/Desktop/NLP_sleep/95806A_6k_rows.csv'\n",
    "process_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32237ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>Total AHI</th>\n",
       "      <th>ESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Epworth:      12/24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Epworth:      11/24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Epworth:      15/24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Epworth: 5/24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Total AHI:  38.3 per hr (Obstructive Index34  ...</td>\n",
       "      <td>38.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           NARRATIVE  Total AHI   ESS\n",
       "0                                Epworth:      12/24        NaN  12.0\n",
       "1                                Epworth:      11/24        NaN  11.0\n",
       "2                                Epworth:      15/24        NaN  15.0\n",
       "3                                      Epworth: 5/24        NaN   5.0\n",
       "4  Total AHI:  38.3 per hr (Obstructive Index34  ...       38.3   NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df = pd.read_csv('extracted_ahi_ess_values.csv')\n",
    "out_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1c78ef9",
   "metadata": {},
   "source": [
    "### 4. Adding missing formats and outputting MRN and PROC_DATE\n",
    "I outputted the MRN and PROC_DATE of each row because it makes it a lot easier to check the accuracy of the program. I also realized that many values were missing because ChatGPT didn't generate all of the formats I provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbf8f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to extract_1.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract AHI and ESS values based on patterns\n",
    "def extract_ahi_ess(text):\n",
    "    ahi_value, ess_value = None, None\n",
    "\n",
    "    # Define AHI patterns based on the given formats\n",
    "    ahi_patterns = [\n",
    "        r'AHI4%:\\s*([\\d\\.]+)',                            # Pattern: AHI4%: 11.1\n",
    "        r'AHI:\\s*\\(total\\)::\\s*([\\d\\.]+)\\s*events/hour',  # Pattern: AHI: (total):: 11.1 events/hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)\\s*per hour',             # Pattern: Total AHI: 11.1 per hour\n",
    "        r'pAHI:\\s*([\\d\\.]+)',                             # Pattern: pAHI: 1.1\n",
    "        r'AHI of\\s*([\\d\\.]+)',                            # Pattern: AHI of 1.1\n",
    "        r'pAHI4%:\\s*([\\d\\.]+)',                           # Pattern: pAHI4%:1.11\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)',                      # Pattern: Total AHI4%: 11.1\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)\\s*per hour',           # Pattern: Overall AHI: 11.1 per hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)',                        # Pattern: Total AHI: 11.1\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)'                       # Pattern: Total AHI4%: 11.1\n",
    "    ]\n",
    "\n",
    "    # Define ESS patterns based on the new formats\n",
    "    ess_patterns = [\n",
    "        r'ESS:\\s*([\\d]+)',                               # Pattern: ESS: 11\n",
    "        r'Epworth Sleepiness Scale\\s*:\\s*([\\d]+)(?:\\s*out of\\s*\\d+)?',  # Pattern: Epworth Sleepiness Scale: 11 out of 24\n",
    "        r'EPWORTH SLEEPINESS SCALE\\s*:\\s*([\\d]+)',       # Pattern: EPWORTH SLEEPINESS SCALE: 11\n",
    "        r'Patient reports ESS of\\s*([\\d]+)',             # Pattern: Patient reports ESS of 11\n",
    "        r'EPWORTH:\\s*([\\d]+)',                           # Pattern: EPWORTH: 11\n",
    "        r'Epworth:\\s*([\\d]+)(?:/\\d+)?',                  # Pattern: Epworth: 11 or Epworth: 11/24\n",
    "        r'Epworth Score:\\s*([\\d]+)'                      # Pattern: Epworth Score: 11\n",
    "    ]\n",
    "\n",
    "    # Search through AHI patterns to find a match\n",
    "    for pattern in ahi_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ahi_value = float(match.group(1))\n",
    "            break\n",
    "\n",
    "    # Search through ESS patterns to find a match\n",
    "    for pattern in ess_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ess_value = int(match.group(1))\n",
    "            break\n",
    "\n",
    "    return ahi_value, ess_value\n",
    "\n",
    "# Function to process a CSV file and extract AHI, ESS, MRN, and PROC_DATE values\n",
    "def process_csv(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if necessary columns exist in the file\n",
    "    required_columns = ['NARRATIVE', 'MRN', 'PROC_DATE']\n",
    "    for col in required_columns:\n",
    "        if col not in data.columns:\n",
    "            print(f\"Error: The CSV file must contain a '{col}' column.\")\n",
    "            return\n",
    "    \n",
    "    # Initialize lists for extracted data\n",
    "    extracted_data = {\n",
    "        \"MRN\": [],\n",
    "        \"PROC_DATE\": [],\n",
    "        \"NARRATIVE\": [],\n",
    "        \"Total AHI\": [],\n",
    "        \"ESS\": []\n",
    "    }\n",
    "    \n",
    "    # Process each row in the CSV file\n",
    "    for index, row in data.iterrows():\n",
    "        narrative_text = str(row['NARRATIVE'])\n",
    "        mrn = row['MRN']\n",
    "        proc_date = row['PROC_DATE']\n",
    "        ahi_value, ess_value = extract_ahi_ess(narrative_text)\n",
    "        \n",
    "        # Append extracted values\n",
    "        extracted_data[\"MRN\"].append(mrn)\n",
    "        extracted_data[\"PROC_DATE\"].append(proc_date)\n",
    "        extracted_data[\"NARRATIVE\"].append(narrative_text)\n",
    "        extracted_data[\"Total AHI\"].append(ahi_value)\n",
    "        extracted_data[\"ESS\"].append(ess_value)\n",
    "    \n",
    "    # Create a DataFrame with the extracted results\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "    \n",
    "    # Remove rows where both 'Total AHI' and 'ESS' are NaN\n",
    "    extracted_df.dropna(subset=[\"Total AHI\", \"ESS\"], how='all', inplace=True)\n",
    "    \n",
    "    # Save the filtered extracted results to a new CSV file\n",
    "    output_path = \"extract_1.csv\"\n",
    "    extracted_df.to_csv(output_path, index=False)\n",
    "    print(f\"Extracted data saved to {output_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming the uploaded file is named 'sleep_study_data.csv'\n",
    "file_path = '/Users/dennishwang/Desktop/NLP_sleep/95806A_6k_rows.csv'\n",
    "process_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d6bf038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRN</th>\n",
       "      <th>PROC_DATE</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>Total AHI</th>\n",
       "      <th>ESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8410</td>\n",
       "      <td>31MAR2010:00:00:00</td>\n",
       "      <td>Total AHI4%:            21.1    (131 minutes)</td>\n",
       "      <td>21.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8410</td>\n",
       "      <td>31MAR2010:00:00:00</td>\n",
       "      <td>Supine AHI4%:         32.6       (97 minutes)</td>\n",
       "      <td>32.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8410</td>\n",
       "      <td>31MAR2010:00:00:00</td>\n",
       "      <td>Non-Supine AHI4%:  10.5         (34 minutes)</td>\n",
       "      <td>10.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8410</td>\n",
       "      <td>31MAR2010:00:00:00</td>\n",
       "      <td>Epworth:      12/24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32809</td>\n",
       "      <td>26JUL2010:00:00:00</td>\n",
       "      <td>Total AHI4%:            2.0    (10 minutes)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MRN           PROC_DATE                                      NARRATIVE  \\\n",
       "0   8410  31MAR2010:00:00:00  Total AHI4%:            21.1    (131 minutes)   \n",
       "1   8410  31MAR2010:00:00:00  Supine AHI4%:         32.6       (97 minutes)   \n",
       "2   8410  31MAR2010:00:00:00   Non-Supine AHI4%:  10.5         (34 minutes)   \n",
       "3   8410  31MAR2010:00:00:00                            Epworth:      12/24   \n",
       "4  32809  26JUL2010:00:00:00    Total AHI4%:            2.0    (10 minutes)   \n",
       "\n",
       "   Total AHI   ESS  \n",
       "0       21.1   NaN  \n",
       "1       32.6   NaN  \n",
       "2       10.5   NaN  \n",
       "3        NaN  12.0  \n",
       "4        2.0   NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_1 = pd.read_csv('extract_1.csv')\n",
    "extract_1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6250cd46",
   "metadata": {},
   "source": [
    "### 5. Removing supine/non-supine values\n",
    "Supine and non-supine values were confusing the program and making it output inaccurate AHI values. To solve this, if the program reads Supine/Non-Supine, it skips the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311d5dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted data saved to extract_3.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract AHI and ESS values based on patterns\n",
    "def extract_ahi_ess(text):\n",
    "    ahi_value, ess_value = None, None\n",
    "\n",
    "    # Check for \"Supine\" or \"Non-Supine\" preceding patterns to skip extraction\n",
    "    if re.search(r'\\b(Supine|Non-Supine)\\b', text, re.IGNORECASE):\n",
    "        return ahi_value, ess_value  # Return None for both, skipping the row\n",
    "\n",
    "    # Define AHI patterns based on the given formats\n",
    "    ahi_patterns = [\n",
    "        r'AHI4%:\\s*([\\d\\.]+)',                            # Pattern: AHI4%: 11.1\n",
    "        r'AHI:\\s*\\(total\\)::\\s*([\\d\\.]+)\\s*events/hour',  # Pattern: AHI: (total):: 11.1 events/hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)\\s*per hour',             # Pattern: Total AHI: 11.1 per hour\n",
    "        r'pAHI:\\s*([\\d\\.]+)',                             # Pattern: pAHI: 1.1\n",
    "        r'AHI of\\s*([\\d\\.]+)',                            # Pattern: AHI of 1.1\n",
    "        r'pAHI4%:\\s*([\\d\\.]+)',                           # Pattern: pAHI4%:1.11\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)',                      # Pattern: Total AHI4%: 11.1\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)\\s*per hour',           # Pattern: Overall AHI: 11.1 per hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)',                        # Pattern: Total AHI: 11.1\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)'                       # Pattern: Total AHI4%: 11.1\n",
    "    ]\n",
    "\n",
    "    # Define ESS patterns based on the new formats\n",
    "    ess_patterns = [\n",
    "        r'ESS:\\s*([\\d]+)',                               # Pattern: ESS: 11\n",
    "        r'Epworth Sleepiness Scale\\s*:\\s*([\\d]+)(?:\\s*out of\\s*\\d+)?',  # Pattern: Epworth Sleepiness Scale: 11 out of 24\n",
    "        r'EPWORTH SLEEPINESS SCALE\\s*:\\s*([\\d]+)',       # Pattern: EPWORTH SLEEPINESS SCALE: 11\n",
    "        r'Patient reports ESS of\\s*([\\d]+)',             # Pattern: Patient reports ESS of 11\n",
    "        r'EPWORTH:\\s*([\\d]+)',                           # Pattern: EPWORTH: 11\n",
    "        r'Epworth:\\s*([\\d]+)(?:/\\d+)?',                  # Pattern: Epworth: 11 or Epworth: 11/24\n",
    "        r'Epworth Score:\\s*([\\d]+)'                      # Pattern: Epworth Score: 11\n",
    "    ]\n",
    "\n",
    "    # Search through AHI patterns to find a match\n",
    "    for pattern in ahi_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ahi_value = float(match.group(1))\n",
    "            break\n",
    "\n",
    "    # Search through ESS patterns to find a match\n",
    "    for pattern in ess_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ess_value = int(match.group(1))\n",
    "            break\n",
    "\n",
    "    return ahi_value, ess_value\n",
    "\n",
    "# Function to process a CSV file and extract AHI, ESS, MRN, and PROC_DATE values\n",
    "def process_csv(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if necessary columns exist in the file\n",
    "    required_columns = ['NARRATIVE', 'MRN', 'PROC_DATE']\n",
    "    for col in required_columns:\n",
    "        if col not in data.columns:\n",
    "            print(f\"Error: The CSV file must contain a '{col}' column.\")\n",
    "            return\n",
    "    \n",
    "    # Initialize lists for extracted data\n",
    "    extracted_data = {\n",
    "        \"MRN\": [],\n",
    "        \"PROC_DATE\": [],\n",
    "        \"NARRATIVE\": [],\n",
    "        \"Total AHI\": [],\n",
    "        \"ESS\": []\n",
    "    }\n",
    "    \n",
    "    # Process each row in the CSV file\n",
    "    for index, row in data.iterrows():\n",
    "        narrative_text = str(row['NARRATIVE'])\n",
    "        mrn = row['MRN']\n",
    "        proc_date = row['PROC_DATE']\n",
    "        ahi_value, ess_value = extract_ahi_ess(narrative_text)\n",
    "        \n",
    "        # Only append rows where at least one of AHI or ESS values is extracted\n",
    "        if ahi_value is not None or ess_value is not None:\n",
    "            extracted_data[\"MRN\"].append(mrn)\n",
    "            extracted_data[\"PROC_DATE\"].append(proc_date)\n",
    "            extracted_data[\"NARRATIVE\"].append(narrative_text)\n",
    "            extracted_data[\"Total AHI\"].append(ahi_value)\n",
    "            extracted_data[\"ESS\"].append(ess_value)\n",
    "    \n",
    "    # Create a DataFrame with the extracted results\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "    \n",
    "    # Remove rows where both 'Total AHI' and 'ESS' are NaN\n",
    "    extracted_df.dropna(subset=[\"Total AHI\", \"ESS\"], how='all', inplace=True)\n",
    "    \n",
    "    # Save the filtered extracted results to a new CSV file\n",
    "    output_path = \"extract_3.csv\"\n",
    "    extracted_df.to_csv(output_path, index=False)\n",
    "    print(f\"Extracted data saved to {output_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming the uploaded file is named 'sleep_study_data.csv'\n",
    "file_path = '/Users/dennishwang/Desktop/NLP_sleep/95806A_6k_rows.csv'\n",
    "process_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c45f79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRN</th>\n",
       "      <th>PROC_DATE</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>Total AHI</th>\n",
       "      <th>ESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8410</td>\n",
       "      <td>31MAR2010:00:00:00</td>\n",
       "      <td>Total AHI4%:            21.1    (131 minutes)</td>\n",
       "      <td>21.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8410</td>\n",
       "      <td>31MAR2010:00:00:00</td>\n",
       "      <td>Epworth:      12/24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32809</td>\n",
       "      <td>26JUL2010:00:00:00</td>\n",
       "      <td>Total AHI4%:            2.0    (10 minutes)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32809</td>\n",
       "      <td>26JUL2010:00:00:00</td>\n",
       "      <td>Epworth:      11/24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101357</td>\n",
       "      <td>09AUG2010:00:00:00</td>\n",
       "      <td>Total AHI4%:            64.3    (465 minutes)</td>\n",
       "      <td>64.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MRN           PROC_DATE                                      NARRATIVE  \\\n",
       "0    8410  31MAR2010:00:00:00  Total AHI4%:            21.1    (131 minutes)   \n",
       "1    8410  31MAR2010:00:00:00                            Epworth:      12/24   \n",
       "2   32809  26JUL2010:00:00:00    Total AHI4%:            2.0    (10 minutes)   \n",
       "3   32809  26JUL2010:00:00:00                            Epworth:      11/24   \n",
       "4  101357  09AUG2010:00:00:00  Total AHI4%:            64.3    (465 minutes)   \n",
       "\n",
       "   Total AHI   ESS  \n",
       "0       21.1   NaN  \n",
       "1        NaN  12.0  \n",
       "2        2.0   NaN  \n",
       "3        NaN  11.0  \n",
       "4       64.3   NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_3 = pd.read_csv('extract_3.csv')\n",
    "extract_3.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1818b064",
   "metadata": {},
   "source": [
    "### 6. Keeping rows with NaN values, combining MRN, and creating \"conversion_error\"\n",
    "I combined the same MRN so we can see an MRN and its respective Total AHI/ESS. I also chose to leave rows with NaN values to see whether the program was messing up or if there actually was no value. When running the program on the entire dataset, there were certain strings the program had issues translating into floats. I replaced those strings initially with a NaN value, but switched it to \"conversion_error\" to be more descriptive and make sure it isn't confused with a missing AHI/ESS value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9375b673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated data saved to extract_5.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract AHI and ESS values based on patterns\n",
    "def extract_ahi_ess(text):\n",
    "    ahi_value, ess_value = None, None\n",
    "\n",
    "    # Check for \"Supine\" or \"Non-Supine\" preceding patterns to skip extraction\n",
    "    if re.search(r'\\b(Supine|Non-Supine)\\b', text, re.IGNORECASE):\n",
    "        return ahi_value, ess_value  # Return None for both, skipping the row\n",
    "\n",
    "    # Define AHI patterns based on the given formats\n",
    "    ahi_patterns = [\n",
    "        r'AHI4%:\\s*([\\d\\.]+)',                            # Pattern: AHI4%: 11.1\n",
    "        r'AHI:\\s*\\(total\\)::\\s*([\\d\\.]+)\\s*events/hour',  # Pattern: AHI: (total):: 11.1 events/hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)\\s*per hour',             # Pattern: Total AHI: 11.1 per hour\n",
    "        r'pAHI:\\s*([\\d\\.]+)',                             # Pattern: pAHI: 1.1\n",
    "        r'AHI of\\s*([\\d\\.]+)',                            # Pattern: AHI of 1.1\n",
    "        r'pAHI4%:\\s*([\\d\\.]+)',                           # Pattern: pAHI4%:1.11\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)',                      # Pattern: Total AHI4%: 11.1\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)\\s*per hour',           # Pattern: Overall AHI: 11.1 per hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)',                        # Pattern: Total AHI: 11.1\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)'                       # Pattern: Total AHI4%: 11.1\n",
    "    ]\n",
    "\n",
    "    # Define ESS patterns based on the new formats\n",
    "    ess_patterns = [\n",
    "        r'ESS:\\s*([\\d]+)',                               # Pattern: ESS: 11\n",
    "        r'Epworth Sleepiness Scale\\s*:\\s*([\\d]+)(?:\\s*out of\\s*\\d+)?',  # Pattern: Epworth Sleepiness Scale: 11 out of 24\n",
    "        r'EPWORTH SLEEPINESS SCALE\\s*:\\s*([\\d]+)',       # Pattern: EPWORTH SLEEPINESS SCALE: 11\n",
    "        r'Patient reports ESS of\\s*([\\d]+)',             # Pattern: Patient reports ESS of 11\n",
    "        r'EPWORTH:\\s*([\\d]+)',                           # Pattern: EPWORTH: 11\n",
    "        r'Epworth:\\s*([\\d]+)(?:/\\d+)?',                  # Pattern: Epworth: 11 or Epworth: 11/24\n",
    "        r'Epworth Score:\\s*([\\d]+)'                      # Pattern: Epworth Score: 11\n",
    "    ]\n",
    "\n",
    "    # Search through AHI patterns to find a match\n",
    "    for pattern in ahi_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ahi_value = float(match.group(1))\n",
    "            break\n",
    "\n",
    "    # Search through ESS patterns to find a match\n",
    "    for pattern in ess_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ess_value = int(match.group(1))\n",
    "            break\n",
    "\n",
    "    return ahi_value, ess_value\n",
    "\n",
    "# Function to process a CSV file and extract AHI, ESS, MRN, and PROC_DATE values, with MRN consolidation\n",
    "def process_csv(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if necessary columns exist in the file\n",
    "    required_columns = ['NARRATIVE', 'MRN', 'PROC_DATE']\n",
    "    for col in required_columns:\n",
    "        if col not in data.columns:\n",
    "            print(f\"Error: The CSV file must contain a '{col}' column.\")\n",
    "            return\n",
    "    \n",
    "    # Initialize lists for extracted data\n",
    "    extracted_data = {\n",
    "        \"MRN\": [],\n",
    "        \"PROC_DATE\": [],\n",
    "        \"NARRATIVE\": [],\n",
    "        \"Total AHI\": [],\n",
    "        \"ESS\": []\n",
    "    }\n",
    "    \n",
    "    # Process each row in the CSV file\n",
    "    for index, row in data.iterrows():\n",
    "        narrative_text = str(row['NARRATIVE'])\n",
    "        mrn = row['MRN']\n",
    "        proc_date = row['PROC_DATE']\n",
    "        ahi_value, ess_value = extract_ahi_ess(narrative_text)\n",
    "        \n",
    "        # Append all rows with or without extracted values\n",
    "        extracted_data[\"MRN\"].append(mrn)\n",
    "        extracted_data[\"PROC_DATE\"].append(proc_date)\n",
    "        extracted_data[\"NARRATIVE\"].append(narrative_text if ahi_value or ess_value else None)\n",
    "        extracted_data[\"Total AHI\"].append(ahi_value)\n",
    "        extracted_data[\"ESS\"].append(ess_value)\n",
    "    \n",
    "    # Create a DataFrame with the extracted results\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    # Consolidate rows with the same MRN\n",
    "    consolidated_df = extracted_df.groupby(\"MRN\").agg({\n",
    "        \"PROC_DATE\": lambda x: ', '.join(map(str, x.unique())),               # Combine unique dates\n",
    "        \"NARRATIVE\": lambda x: '; '.join(filter(None, x)),                    # Combine narratives\n",
    "        \"Total AHI\": \"first\",                                                 # Use first non-NaN AHI\n",
    "        \"ESS\": \"first\"                                                        # Use first non-NaN ESS\n",
    "    }).reset_index()\n",
    "\n",
    "    # Ensure that even MRNs without AHI or ESS are kept, with NaNs if necessary\n",
    "    consolidated_df[\"Total AHI\"] = consolidated_df[\"Total AHI\"].fillna(\"NaN\")\n",
    "    consolidated_df[\"ESS\"] = consolidated_df[\"ESS\"].fillna(\"NaN\")\n",
    "    consolidated_df[\"NARRATIVE\"] = consolidated_df[\"NARRATIVE\"].apply(lambda x: x if x else \"NaN\")\n",
    "\n",
    "    # Save the consolidated extracted results to a new CSV file\n",
    "    output_path = \"extract_5.csv\"\n",
    "    consolidated_df.to_csv(output_path, index=False)\n",
    "    print(f\"Consolidated data saved to {output_path}\")\n",
    "\n",
    "# Example usage:\n",
    "# Assuming the uploaded file is named 'sleep_study_data.csv'\n",
    "file_path = '/Users/dennishwang/Desktop/NLP_sleep/95806A_6k_rows.csv'\n",
    "process_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea048790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRN</th>\n",
       "      <th>PROC_DATE</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>Total AHI</th>\n",
       "      <th>ESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3646</td>\n",
       "      <td>16NOV2015:00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8410</td>\n",
       "      <td>31MAR2010:00:00:00</td>\n",
       "      <td>Total AHI4%:            21.1    (131 minutes);...</td>\n",
       "      <td>21.1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17844</td>\n",
       "      <td>04APR2016:00:00:00</td>\n",
       "      <td>Total AHI4%: 11.1; AHI4%: 11.1; ODI4%: 16.1; T...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17895</td>\n",
       "      <td>13JAN2011:00:00:00</td>\n",
       "      <td>Neck Circumference: 19.5 inch.   Epworth Score...</td>\n",
       "      <td>44.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18652</td>\n",
       "      <td>23JUL2015:00:00:00</td>\n",
       "      <td>Total AHI4%: 72.6; AHI4%: 72.6 ODI4%: 58.5 T90...</td>\n",
       "      <td>72.6</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MRN           PROC_DATE  \\\n",
       "0   3646  16NOV2015:00:00:00   \n",
       "1   8410  31MAR2010:00:00:00   \n",
       "2  17844  04APR2016:00:00:00   \n",
       "3  17895  13JAN2011:00:00:00   \n",
       "4  18652  23JUL2015:00:00:00   \n",
       "\n",
       "                                           NARRATIVE  Total AHI   ESS  \n",
       "0                                                NaN        NaN   NaN  \n",
       "1  Total AHI4%:            21.1    (131 minutes);...       21.1  12.0  \n",
       "2  Total AHI4%: 11.1; AHI4%: 11.1; ODI4%: 16.1; T...       11.1  11.0  \n",
       "3  Neck Circumference: 19.5 inch.   Epworth Score...       44.8   3.0  \n",
       "4  Total AHI4%: 72.6; AHI4%: 72.6 ODI4%: 58.5 T90...       72.6  10.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_5 = pd.read_csv('extract_5.csv')\n",
    "extract_5.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cb8ac1b",
   "metadata": {},
   "source": [
    "## Final Version (Keep all MRNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5eb0273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated data with all rows saved to final_all_mrn.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract AHI and ESS values based on patterns with validation\n",
    "def extract_ahi_ess(text):\n",
    "    ahi_value, ess_value = None, None\n",
    "\n",
    "    # Check for \"Supine\" or \"Non-Supine\" preceding patterns to skip extraction\n",
    "    if re.search(r'\\b(Supine|Non-Supine)\\b', text, re.IGNORECASE):\n",
    "        return ahi_value, ess_value  # Return None for both, skipping the row\n",
    "\n",
    "    # Define AHI patterns based on the given formats\n",
    "    ahi_patterns = [\n",
    "        r'AHI4%:\\s*([\\d\\.]+)',                            # Pattern: AHI4%: 11.1\n",
    "        r'AHI:\\s*\\(total\\)::\\s*([\\d\\.]+)\\s*events/hour',  # Pattern: AHI: (total):: 11.1 events/hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)\\s*per hour',             # Pattern: Total AHI: 11.1 per hour\n",
    "        r'pAHI:\\s*([\\d\\.]+)',                             # Pattern: pAHI: 1.1\n",
    "        r'AHI of\\s*([\\d\\.]+)',                            # Pattern: AHI of 1.1\n",
    "        r'pAHI4%:\\s*([\\d\\.]+)',                           # Pattern: pAHI4%:1.11\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)',                      # Pattern: Total AHI4%: 11.1\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)\\s*per hour',           # Pattern: Overall AHI: 11.1 per hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)',                        # Pattern: Total AHI: 11.1\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)',                      # Pattern: Total AHI4%: 11.1\n",
    "        r'Apnea / Hypopnea Index\\s*([\\d\\.]+)',            # New: Apnea / Hypopnea Index 16.6\n",
    "        r'AHI\\s*([\\d\\.]+)\\s*(?:REM AHI [\\d\\.]+)?\\s*(?:RDI [\\d\\.]+)?', # New: AHI 43.9 (ignore REM AHI and RDI)\n",
    "        r'Respirations:\\s*AHI4%\\s*([\\d\\.]+)\\s*\\(supine [\\d\\.]+;\\s*non-supine [\\d\\.]+\\)', # New: Respirations AHI4%\n",
    "    ]\n",
    "\n",
    "    # Define ESS patterns with the new format\n",
    "    ess_patterns = [\n",
    "        r'ESS:\\s*([\\d]+)',                               # Pattern: ESS: 11\n",
    "        r'Epworth Sleepiness Scale\\s*:\\s*([\\d]+)(?:\\s*out of\\s*\\d+)?',  # Pattern: Epworth Sleepiness Scale: 11 out of 24\n",
    "        r'EPWORTH SLEEPINESS SCALE\\s*:\\s*([\\d]+)',       # Pattern: EPWORTH SLEEPINESS SCALE: 11\n",
    "        r'Patient reports ESS of\\s*([\\d]+)',             # Pattern: Patient reports ESS of 11\n",
    "        r'EPWORTH:\\s*([\\d]+)',                           # Pattern: EPWORTH: 11\n",
    "        r'Epworth:\\s*([\\d]+)(?:/\\d+)?',                  # Pattern: Epworth: 11 or Epworth: 11/24\n",
    "        r'Epworth Score:\\s*([\\d]+)',                     # Pattern: Epworth Score: 11\n",
    "        r'Epworth\\s*([\\d]+)(?:/\\d+)?'                    # New: Epworth 10/24\n",
    "    ]\n",
    "\n",
    "    # Search through AHI patterns to find a match\n",
    "    for pattern in ahi_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ahi_candidate = match.group(1)\n",
    "            # Validate that ahi_candidate is a valid number (no multiple decimal points)\n",
    "            if re.match(r'^\\d+(\\.\\d+)?$', ahi_candidate):  # Matches integers or floats with only one decimal\n",
    "                ahi_value = float(ahi_candidate)\n",
    "            else:\n",
    "                ahi_value = \"conversion_error\"\n",
    "            break\n",
    "\n",
    "    # Search through ESS patterns to find a match\n",
    "    for pattern in ess_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ess_candidate = match.group(1)\n",
    "            if re.match(r'^\\d+$', ess_candidate):  # Matches integers only\n",
    "                ess_value = int(ess_candidate)\n",
    "            else:\n",
    "                ess_value = \"conversion_error\"\n",
    "            break\n",
    "\n",
    "    return ahi_value, ess_value\n",
    "\n",
    "# Function to process a CSV file and extract AHI, ESS, MRN, and PROC_DATE values, keeping all rows\n",
    "def process_csv_keep_all(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if necessary columns exist in the file\n",
    "    required_columns = ['NARRATIVE', 'MRN', 'PROC_DATE']\n",
    "    for col in required_columns:\n",
    "        if col not in data.columns:\n",
    "            print(f\"Error: The CSV file must contain a '{col}' column.\")\n",
    "            return\n",
    "    \n",
    "    # Initialize lists for extracted data\n",
    "    extracted_data = {\n",
    "        \"MRN\": [],\n",
    "        \"PROC_DATE\": [],\n",
    "        \"NARRATIVE\": [],\n",
    "        \"Total AHI\": [],\n",
    "        \"ESS\": []\n",
    "    }\n",
    "    \n",
    "    # Process each row in the CSV file\n",
    "    for index, row in data.iterrows():\n",
    "        narrative_text = str(row['NARRATIVE'])\n",
    "        mrn = row['MRN']\n",
    "        proc_date = row['PROC_DATE']\n",
    "        ahi_value, ess_value = extract_ahi_ess(narrative_text)\n",
    "        \n",
    "        # Append all rows with or without extracted values\n",
    "        extracted_data[\"MRN\"].append(mrn)\n",
    "        extracted_data[\"PROC_DATE\"].append(proc_date)\n",
    "        extracted_data[\"NARRATIVE\"].append(narrative_text)\n",
    "        extracted_data[\"Total AHI\"].append(ahi_value)\n",
    "        extracted_data[\"ESS\"].append(ess_value)\n",
    "    \n",
    "    # Create a DataFrame with the extracted results\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    # Consolidate rows with the same MRN\n",
    "    consolidated_df = extracted_df.groupby(\"MRN\").agg({\n",
    "        \"PROC_DATE\": lambda x: ', '.join(map(str, x.unique())),               # Combine unique dates\n",
    "        \"NARRATIVE\": lambda x: '; '.join(filter(None, x)),                    # Combine narratives\n",
    "        \"Total AHI\": \"first\",                                                 # Use first non-NaN AHI or conversion_error\n",
    "        \"ESS\": \"first\"                                                        # Use first non-NaN ESS or conversion_error\n",
    "    }).reset_index()\n",
    "\n",
    "    # Save the consolidated extracted results to a new CSV file\n",
    "    output_path = \"final_all_mrn.csv\"\n",
    "    consolidated_df.to_csv(output_path, index=False)\n",
    "    print(f\"Consolidated data with all rows saved to {output_path}\")\n",
    "\n",
    "# Example usage for all rows:\n",
    "file_path = '/Users/dennishwang/Desktop/NLP_sleep/sleepstudies.csv'\n",
    "process_csv_keep_all(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5aa537b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRN</th>\n",
       "      <th>PROC_DATE</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>Total AHI</th>\n",
       "      <th>ESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3646</td>\n",
       "      <td>16NOV2015:00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8410</td>\n",
       "      <td>31MAR2010:00:00:00</td>\n",
       "      <td>Name: Frank Horzen; Date of Birth: 30.12.1942;...</td>\n",
       "      <td>21.1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10011</td>\n",
       "      <td>12FEB2008:00:00:00</td>\n",
       "      <td>Kaiser Permanente Sleep Laboratory; 9985 N. Si...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15778</td>\n",
       "      <td>15DEC2014:00:00:00</td>\n",
       "      <td>Ambulatory Sleep Study; Study conducted as an ...</td>\n",
       "      <td>18.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17844</td>\n",
       "      <td>04APR2016:00:00:00</td>\n",
       "      <td>PATIENT INFORMATION; nan; Name: Medina, Julian...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MRN           PROC_DATE  \\\n",
       "0   3646  16NOV2015:00:00:00   \n",
       "1   8410  31MAR2010:00:00:00   \n",
       "2  10011  12FEB2008:00:00:00   \n",
       "3  15778  15DEC2014:00:00:00   \n",
       "4  17844  04APR2016:00:00:00   \n",
       "\n",
       "                                           NARRATIVE Total AHI   ESS  \n",
       "0                                                NaN       NaN   NaN  \n",
       "1  Name: Frank Horzen; Date of Birth: 30.12.1942;...      21.1  12.0  \n",
       "2  Kaiser Permanente Sleep Laboratory; 9985 N. Si...       8.9   NaN  \n",
       "3  Ambulatory Sleep Study; Study conducted as an ...      18.5   NaN  \n",
       "4  PATIENT INFORMATION; nan; Name: Medina, Julian...      11.1  11.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_all_mrn = pd.read_csv('final_all_mrn.csv')\n",
    "final_all_mrn.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66d4bfb5",
   "metadata": {},
   "source": [
    "## Remove MRNs with all NaNs\n",
    "Removed every row where Total_AHI = NaN and ESS = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4df57033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated data (excluding rows without AHI or ESS) saved to final_no_nan_mrn.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract AHI and ESS values based on patterns with validation\n",
    "def extract_ahi_ess(text):\n",
    "    ahi_value, ess_value = None, None\n",
    "\n",
    "    # Check for \"Supine\" or \"Non-Supine\" preceding patterns to skip extraction\n",
    "    if re.search(r'\\b(Supine|Non-Supine)\\b', text, re.IGNORECASE):\n",
    "        return ahi_value, ess_value  # Return None for both, skipping the row\n",
    "\n",
    "    # Define AHI patterns based on the given formats\n",
    "    ahi_patterns = [\n",
    "        r'AHI4%:\\s*([\\d\\.]+)',                            # Pattern: AHI4%: 11.1\n",
    "        r'AHI:\\s*\\(total\\)::\\s*([\\d\\.]+)\\s*events/hour',  # Pattern: AHI: (total):: 11.1 events/hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)\\s*per hour',             # Pattern: Total AHI: 11.1 per hour\n",
    "        r'pAHI:\\s*([\\d\\.]+)',                             # Pattern: pAHI: 1.1\n",
    "        r'AHI of\\s*([\\d\\.]+)',                            # Pattern: AHI of 1.1\n",
    "        r'pAHI4%:\\s*([\\d\\.]+)',                           # Pattern: pAHI4%:1.11\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)',                      # Pattern: Total AHI4%: 11.1\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)\\s*per hour',           # Pattern: Overall AHI: 11.1 per hour\n",
    "        r'Overall AHI:\\s*([\\d\\.]+)',                      # Pattern: Overall AHI: 11.1\n",
    "        r'Total AHI:\\s*([\\d\\.]+)',                        # Pattern: Total AHI: 11.1\n",
    "        r'Total AHI4%:\\s*([\\d\\.]+)'                       # Pattern: Total AHI4%: 11.1\n",
    "    ]\n",
    "\n",
    "    # Define ESS patterns based on the new formats\n",
    "    ess_patterns = [\n",
    "        r'ESS:\\s*([\\d]+)',                               # Pattern: ESS: 11\n",
    "        r'Epworth Sleepiness Scale\\s*:\\s*([\\d]+)(?:\\s*out of\\s*\\d+)?',  # Pattern: Epworth Sleepiness Scale: 11 out of 24\n",
    "        r'EPWORTH SLEEPINESS SCALE\\s*:\\s*([\\d]+)',       # Pattern: EPWORTH SLEEPINESS SCALE: 11\n",
    "        r'Patient reports ESS of\\s*([\\d]+)',             # Pattern: Patient reports ESS of 11\n",
    "        r'EPWORTH:\\s*([\\d]+)',                           # Pattern: EPWORTH: 11\n",
    "        r'Epworth:\\s*([\\d]+)(?:/\\d+)?',                  # Pattern: Epworth: 11 or Epworth: 11/24\n",
    "        r'Epworth Score:\\s*([\\d]+)'                      # Pattern: Epworth Score: 11\n",
    "    ]\n",
    "\n",
    "    # Search through AHI patterns to find a match\n",
    "    for pattern in ahi_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ahi_candidate = match.group(1)\n",
    "            # Validate that ahi_candidate is a valid number (no multiple decimal points)\n",
    "            if re.match(r'^\\d+(\\.\\d+)?$', ahi_candidate):  # Matches integers or floats with only one decimal\n",
    "                ahi_value = float(ahi_candidate)\n",
    "            else:\n",
    "                ahi_value = \"conversion_error\"\n",
    "            break\n",
    "\n",
    "    # Search through ESS patterns to find a match\n",
    "    for pattern in ess_patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            ess_candidate = match.group(1)\n",
    "            if re.match(r'^\\d+$', ess_candidate):  # Matches integers only\n",
    "                ess_value = int(ess_candidate)\n",
    "            else:\n",
    "                ess_value = \"conversion_error\"\n",
    "            break\n",
    "\n",
    "    return ahi_value, ess_value\n",
    "\n",
    "# Function to process a CSV file and extract AHI, ESS, MRN, and PROC_DATE values, excluding rows without AHI or ESS\n",
    "def process_csv_exclude_empty(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if necessary columns exist in the file\n",
    "    required_columns = ['NARRATIVE', 'MRN', 'PROC_DATE']\n",
    "    for col in required_columns:\n",
    "        if col not in data.columns:\n",
    "            print(f\"Error: The CSV file must contain a '{col}' column.\")\n",
    "            return\n",
    "    \n",
    "    # Initialize lists for extracted data\n",
    "    extracted_data = {\n",
    "        \"MRN\": [],\n",
    "        \"PROC_DATE\": [],\n",
    "        \"NARRATIVE\": [],\n",
    "        \"Total AHI\": [],\n",
    "        \"ESS\": []\n",
    "    }\n",
    "    \n",
    "    # Process each row in the CSV file\n",
    "    for index, row in data.iterrows():\n",
    "        narrative_text = str(row['NARRATIVE'])\n",
    "        mrn = row['MRN']\n",
    "        proc_date = row['PROC_DATE']\n",
    "        ahi_value, ess_value = extract_ahi_ess(narrative_text)\n",
    "        \n",
    "        # Only append rows with at least one valid AHI or ESS value\n",
    "        if ahi_value is not None or ess_value is not None:\n",
    "            extracted_data[\"MRN\"].append(mrn)\n",
    "            extracted_data[\"PROC_DATE\"].append(proc_date)\n",
    "            extracted_data[\"NARRATIVE\"].append(narrative_text)\n",
    "            extracted_data[\"Total AHI\"].append(ahi_value)\n",
    "            extracted_data[\"ESS\"].append(ess_value)\n",
    "    \n",
    "    # Create a DataFrame with the extracted results\n",
    "    extracted_df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    # Consolidate rows with the same MRN\n",
    "    consolidated_df = extracted_df.groupby(\"MRN\").agg({\n",
    "        \"PROC_DATE\": lambda x: ', '.join(map(str, x.unique())),               # Combine unique dates\n",
    "        \"NARRATIVE\": lambda x: '; '.join(filter(None, x)),                    # Combine narratives\n",
    "        \"Total AHI\": \"first\",                                                 # Use first non-NaN AHI or conversion_error\n",
    "        \"ESS\": \"first\"                                                        # Use first non-NaN ESS or conversion_error\n",
    "    }).reset_index()\n",
    "\n",
    "    # Save the consolidated extracted results to a new CSV file\n",
    "    output_path = \"final_no_nan_mrn.csv\"\n",
    "    consolidated_df.to_csv(output_path, index=False)\n",
    "    print(f\"Consolidated data (excluding rows without AHI or ESS) saved to {output_path}\")\n",
    "\n",
    "# Example usage for excluding rows without AHI or ESS:\n",
    "file_path = '/Users/dennishwang/Desktop/NLP_sleep/sleepstudies.csv'\n",
    "process_csv_exclude_empty(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c0cef2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MRN</th>\n",
       "      <th>PROC_DATE</th>\n",
       "      <th>NARRATIVE</th>\n",
       "      <th>Total AHI</th>\n",
       "      <th>ESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8410</td>\n",
       "      <td>31MAR2010:00:00:00</td>\n",
       "      <td>Total AHI4%:            21.1    (131 minutes);...</td>\n",
       "      <td>21.1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15778</td>\n",
       "      <td>15DEC2014:00:00:00</td>\n",
       "      <td>Overall AHI:  18.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17844</td>\n",
       "      <td>04APR2016:00:00:00</td>\n",
       "      <td>Total AHI4%: 11.1; AHI4%: 11.1; ODI4%: 16.1; T...</td>\n",
       "      <td>11.1</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17895</td>\n",
       "      <td>13JAN2011:00:00:00</td>\n",
       "      <td>Neck Circumference: 19.5 inch.   Epworth Score...</td>\n",
       "      <td>44.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18652</td>\n",
       "      <td>23JUL2015:00:00:00</td>\n",
       "      <td>Total AHI4%: 72.6; AHI4%: 72.6 ODI4%: 58.5 T90...</td>\n",
       "      <td>72.6</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MRN           PROC_DATE  \\\n",
       "0   8410  31MAR2010:00:00:00   \n",
       "1  15778  15DEC2014:00:00:00   \n",
       "2  17844  04APR2016:00:00:00   \n",
       "3  17895  13JAN2011:00:00:00   \n",
       "4  18652  23JUL2015:00:00:00   \n",
       "\n",
       "                                           NARRATIVE Total AHI   ESS  \n",
       "0  Total AHI4%:            21.1    (131 minutes);...      21.1  12.0  \n",
       "1                                 Overall AHI:  18.5      18.5   NaN  \n",
       "2  Total AHI4%: 11.1; AHI4%: 11.1; ODI4%: 16.1; T...      11.1  11.0  \n",
       "3  Neck Circumference: 19.5 inch.   Epworth Score...      44.8   3.0  \n",
       "4  Total AHI4%: 72.6; AHI4%: 72.6 ODI4%: 58.5 T90...      72.6  10.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_no_nan_mrn = pd.read_csv('final_no_nan_mrn.csv')\n",
    "final_no_nan_mrn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4e47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
